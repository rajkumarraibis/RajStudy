
````markdown
# ğŸ“˜ Why I Liked Delta Live Tables in Databricks  
*by Mariusz Kujawski*  
ğŸ”— [Read the original article on Medium](https://medium.com/@mariusz_kujawski/why-i-liked-delta-live-tables-in-databricks-b55b5a97c55c)

---

## Introduction

Databricks has created something that every data engineer will love: **Delta Live Tables (DLT)**.

DLT enables you to declare data transformations using simple SQL or Python and orchestrate your pipeline with built-in monitoring, testing, and error handling. Let's go through why it's awesome.

---

## ğŸ”¹ Orchestration in DLT

DLT eliminates the need for external orchestration tools like Apache Airflow or Azure Data Factory.

> Instead of building DAGs manually, your DLT pipeline is the DAG!

ğŸ“·  
![DLT DAG with SQL and Python pipelines](\images\dlt_dag.png)

---

## ğŸ” Built-in Monitoring and Observability

With DLT, you get monitoring out of the box. You can view the status of your tables, lineage, and metrics in a clean UI.

ğŸ“·  
![DLT UI with table status and progress](\images\dlt_ui_monitoring.png)

---

## âš™ï¸ Testing & Data Quality Rules

DLT supports data quality rules natively:

```sql
CREATE OR REFRESH LIVE bronze_table
AS SELECT *
FROM cloud_files("/path", "json")
CONSTRAINT valid_data EXPECT (id IS NOT NULL);
````

You can flag or drop invalid rows easily and log the violations.

ğŸ“·
![DLT test rule UI](\images\dlt_data_quality.png)

---

## ğŸ§ª Development Flow

With DLT, you can develop in "development" mode and deploy confidently in "production" mode using the same code.

* Fast iteration during development.
* Version-controlled deployment in production.

ğŸ“·
![DLT development and production modes](\images\dlt_dev_prod.png)

---

## ğŸ”„ Auto Scaling & Error Recovery

DLT handles job retries, cluster restarts, and retries automatically. You focus on logic, Databricks takes care of operations.

ğŸ“·
![DLT pipeline error handling](\images\dlt_autoscale.png)

---

## ğŸ§± SQL or Python â€” Your Choice

You can choose SQL:

```sql
CREATE OR REFRESH LIVE gold_users
AS SELECT * FROM silver_users WHERE is_active = true
```

Or Python:

```python
@dlt.table
def gold_users():
    return spark.sql("SELECT * FROM silver_users WHERE is_active = true")
```

ğŸ“·
![SQL and Python examples](\images\dlt_sql_python.png)

---

## âœ… Summary

Delta Live Tables:

* Remove orchestration overhead
* Provide visibility and monitoring
* Support data quality rules
* Handle retries and errors
* Work with SQL and Python
* Accelerate development and deployment

If youâ€™re building data pipelines â€” DLT is worth exploring!

---

ğŸ“š **Reference**
[Why I Liked Delta Live Tables in Databricks â€“ Medium Article](https://medium.com/@mariusz_kujawski/why-i-liked-delta-live-tables-in-databricks-b55b5a97c55c)

```

---
