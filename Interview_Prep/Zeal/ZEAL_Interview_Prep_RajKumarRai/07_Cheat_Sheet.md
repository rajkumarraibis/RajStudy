# ZEAL Interview Cheat Sheet â€“ Raj Kumar Rai

This 30-minute call is about **technical alignment + collaboration fit**. Keep answers concise (~1â€“2 minutes each) and end with a value statement.

---
## ğŸ”¹ Top Technical Topics
1. **Data Architecture:** Scalable AWSâ€“Databricksâ€“S3 design, clear ingestion/processing/serving layers.
2. **Airflow & DataOps:** Reliability, automation, testing, observability.
3. **Kafka / Real-time:** Event-driven design, schema management, idempotency.
4. **dbt & Data Warehouse:** Modular transformations, CI/CD, testing, lineage.
5. **Collaboration:** Ownership, mentoring, and cross-functional delivery.

---
## ğŸ’¬ Sample Questions & Model Answers

### 1. Tell me about your current data platform.
> â€œAt Freeletics, our AWS-based platform ingests data from multiple sources via Lambda/Kinesis into S3. Spark (Databricks) performs enrichment and aggregation, structured into Bronzeâ€“Silverâ€“Gold zones. Airflow orchestrates daily jobs, and analysts consume via Databricks SQL or Athena.â€

### 2. How do you ensure data quality?
> â€œWe integrate validation tasks in Airflow using Great Expectations and schema checks during ingestion. Any deviation triggers Slack alerts and stops downstream jobs.â€

### 3. How do you design reliable Airflow DAGs?
> â€œEach DAG is modular, with explicit dependencies and retries. I use dynamic task generation for daily runs and integrate Slack + CloudWatch for monitoring.â€

### 4. Describe your experience with Kafka or streaming.
> â€œIâ€™ve implemented Kinesis-based enrichment similar to Kafka â€” schema-defined, idempotent, with replay mechanisms. This pattern scales easily for user events or transaction pipelines.â€

### 5. How do you apply DataOps / GitOps in practice?
> â€œAll DAGs, dbt models, and config files are versioned in Git. Deployments happen via CI/CD with automatic validation â€” no manual changes in production.â€

### 6. Whatâ€™s your experience with dbt or modular data modeling?
> â€œWe follow dbt-style modeling in Databricks SQL â€” layered design, version control, and automated testing â€” so onboarding to dbt would be natural.â€

### 7. How do you collaborate with Data Scientists?
> â€œI help design feature-ready datasets and ensure reliable refresh logic. We coordinate through shared schema repos and clear SLAs.â€

### 8. Tell me about a project youâ€™re proud of.
> â€œThe Apple transaction enrichment pipeline. I eliminated retries to avoid duplicates, captured detailed per-user logs to S3, and improved reliability â€” a strong DataOps win.â€

### 9. Whatâ€™s your leadership style?
> â€œServant-leadership â€” I mentor engineers, ensure clarity, and create an environment where reliability and autonomy go hand-in-hand.â€

### 10. Why ZEAL?
> â€œZEALâ€™s modern data stack â€” Airflow, dbt, Kafka, Data Mesh â€” aligns perfectly with what Iâ€™ve built at Freeletics. Iâ€™d love to contribute to scaling it further with automation and reliability.â€

---
## âš¡ Key Phrases to Drop
- â€œModern Data Stack mindset.â€
- â€œData Mesh and domain ownership.â€
- â€œDataOps maturity â€” automation, testing, observability.â€
- â€œEnd-to-end ownership and measurable reliability.â€
- â€œCI/CD-driven data pipelines.â€

---
## ğŸ¯ Mindset to Show
âœ… Strategic, collaborative, data-obsessed, automation-driven.  
âŒ Not overly tactical or tool-focused.  
End strong with: *â€œI love building reliable, high-impact data ecosystems that empower teams and scale with the business.â€*
